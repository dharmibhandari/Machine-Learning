# Problem Statement-Predicting if a person have heart disease using Support Vector machine

# step 1 -Import required libraries

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # data visualization
%matplotlib inline
import seaborn as sns # statistical data visualization
from sklearn.ensemble import RandomForestClassifier




# step 2 = read Data

df = pd.read_csv(r"/content/sample_data/rf.csv")

df.head()

df.info()

df.describe()

df.columns

# check the null value

df.isnull().sum()

# create features and target data

X = df.drop(['target'], axis=1)

y = df['target']

# Divide into training and testing data

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

# check the shape of X_train and X_test

X_train.shape, X_test.shape

rfc = RandomForestClassifier(random_state=0)
rfc.fit(X_train,y_train)

df.columns

## Feature Scaling

from sklearn.preprocessing import MinMaxScaler

scaling = MinMaxScaler()

scaling = scaling.fit_transform(df[['age', 'trestbps', 'chol', 'thalach', 'oldpeak']])


def

scaling

y_pred = rfc.predict(X_test)

y_pred

from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_pred)

# parameter n_estimators=1000

rfc_100 = RandomForestClassifier(n_estimators=1000, random_state=0)


rfc_100.fit(X_train, y_train)

y_pred_100 = rfc_100.predict(X_test)
print('Model accuracy score with 1000 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_100)

print('Confusion matrix\n\n', cm)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_100))

Init signature:
RandomForestClassifier(
    n_estimators=100,
    *,
    criterion='gini',
    max_depth=None,
    min_samples_split=2,
    min_samples_leaf=1,

def decision_tree_model(para):
    results = []
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
    for criterion in para['criterion']:
        for max_depth in para['max_depth']:
            for min_samples_split in para['min_samples_split']:
                model = RandomForestClassifier(
                    criterion=criterion,
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=42
                )

                model.fit(X_train, y_train)

                train_accuracy = model.score(X_train, y_train)
                test_accuracy = model.score(X_test, y_test)

                results.append({
                    'n_estimator':n_estimator,
                    'criterion': criterion,
                    'max_depth': max_depth,
                    'min_samples_split': min_samples_split,
                    'train_accuracy': train_accuracy,
                    'test_accura  cy': test_accuracy
                })

    result_df = pd.DataFrame(results)
    return result_df



para = { 'n_estimator':[100],
    'criterion': ["gini", "entropy"],
    'max_depth': [3, 4, 5, 6],
    'min_samples_split': [2, 3, 4, 5]}

df = decision_tree_model(para)
print(df)
